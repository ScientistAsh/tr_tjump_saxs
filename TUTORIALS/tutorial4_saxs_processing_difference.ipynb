{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05698196-cbe0-4693-bbe3-cecd0303f1ff",
   "metadata": {},
   "source": [
    "# Tutorial 4: Data Processing for Time Resolved, Temperature-Jump SAXS Difference Curves\n",
    "\n",
    "**Package Information:**<br>\n",
    "Currently the [tr_tjump_saxs](https://gitlab.oit.duke.edu/tr_t-jump_saxs/y22-23/-/tree/main?ref_type=heads \"tr_tjump_saxs\") package only works through the Python3 command line. The full dependencies can be found on the [Henderson GitLab Page](https://gitlab.oit.duke.edu/tr_t-jump_saxs/y22-23/-/tree/main?ref_type=heads \"tr_tjump_saxs\") and the environment can be cloned from the [environment.yml file](https://gitlab.oit.duke.edu/tr_t-jump_saxs/y22-23/-/blob/main/environment.yml?ref_type=heads \"environment.yml file\"). The data analysis can be executed from an interactive Python command line such as [iPython](https://www.python.org/) or [Jupyter](https://jupyter.org/) or the code can be written in a script to run in a non-interactive mode. The preferred usage is in Jupyter Lab as this is the environment the package was developed in. Jupyter also provides a file where all code, output of code, and notes can be contained in a single file and serves a record of the data analysis performed, the code used to conduct the data analysis, and the output of the analysis. \n",
    "\n",
    "**Tutorial Information:**<br>\n",
    "This set of tutorial notebooks will cover how to use the `tr_tjump_saxs` package to analyze TR, T-Jump SAXS data and the <a href=\"https://www.science.org/doi/10.1126/sciadv.adj0396\">workflow used to study HIV-1 Envelope glycoprotein dynamics. </a> This package contains multiple modules, each containing a set of functions to accomplish a specific subtask of the TR, T-Jump SAXS data analysis workflow. Many of the functions are modular and some can be helpful for analyzing static SAXS and other data sets as well.  \n",
    "\n",
    "**Package Modules:**<br>\n",
    "> 1. `file_handling`<br>\n",
    "> 2. `saxs_processing`<br>\n",
    "> 3. `saxs_qc`<br>\n",
    "> 4. `saxs_kinetics`<br>\n",
    "> 5. `saxs_modeling`<br>\n",
    "\n",
    "**Developer:** [@ScientistAsh](https://github.com/ScientistAsh \"ScientistAsh GitHub\")\n",
    "\n",
    "**Updated:** 6 February 2024\n",
    "\n",
    "# Tutorial 4 Introduction\n",
    "In the Tutorial 3 + 4 notebooks, I introduce the `saxs_processing` module from the `tr_tjump_saxs` package. This tutorial will cover processing SAXS difference curves from T-jump experiments. The `saxs_processing` module provides functions that will find and remove outliers, scale curves, and subtract curves. This tutorial assumes that you have finished the first two tutorials. If you need help with loading files or processing SAXS scattering curves, see the relevant [tutorials](https://gitlab.oit.duke.edu/tr_t-jump_saxs/y22-23/-/tree/main/TUTORIALS?ref_type=heads). If you find any issues with this tutorial or module, please create an issue on the repository GitLab page ([tr_tjump_saxs issues](https://gitlab.oit.duke.edu/tr_t-jump_saxs/y22-23/-/issues \"tr_tjump_saxs Issues\")). \n",
    "\n",
    "# Module functions:\n",
    "> 1. `svd_outliers()` uses and SVD method to determine outliers in scattering curves. <br>\n",
    "> 2. `iterative_chi()` uses a $\\chi^2$ method to determine outliers in T-Jump difference curves . <br>\n",
    "> 3. `saxs_scale()` scales a given curve to a given reference curve. <br>\n",
    "> 4. `saxs_sub()` subtracts a given curve from a reference curve. <br>\n",
    "> 5. `auc_outliers()` will determine the outliers of a given data set using an area under the curve method.$^*$ <br>\n",
    "> 6. `move_outliers()` will move the outlier files to a given directory for quarantine. This is not recommended because files can get lost easily.$^*$ <br>\n",
    "\n",
    "$^*$Please note that the `move_outliers` and `auc_outliers` functions are no longer used and will not be maintained and not recommended for use.\n",
    "\n",
    "# Tutorial Data Files:\n",
    "\n",
    "### Data Files\n",
    "The original data used in this analysis is deposited on the [SASBDB](https://www.sasbdb.org/) with accession numbers:\n",
    "> **Static Data:** <br>\n",
    "    - *CH505 Temperature Sereies*: SASDT29, SASDT39, SASDT49, SASDT59 <br>\n",
    "    - *CH848 Temperature Series*: SASDTH9, SASDTJ9, SASDTK9, SASDTL9 <br>\n",
    "<br>\n",
    "> **T-Jump Data:** <br>\n",
    "    - *CH505 T-Jump Data*: SASDT69, SASDT79, SASDT89, SASDT99, SASDTA9, SASDTB9, SASDTC9, SASDTD9, SASDTE9, SASDTF9, SASDTG9 <br>\n",
    "     - *CH848 T-Jump Data*: SASDTM9, SASDTN9, SASDTP9, SASDTQ9, SASDTR9, SASDTS9, SASDTT9, SASDTU9, SASDTV9, SASDTW9 <br>\n",
    "<br>\n",
    "> **Static Env SOSIP Panel:** SASDTZ9, SASDU22, SASDU32, SASDU42, SASDTX9, SASDTY9 <br>\n",
    "\n",
    "Additional MD data associated with the paper can be found on [Zenodo](https://zenodo.org/records/10451687).\n",
    "\n",
    "### Output Files\n",
    "Example output is included in the [OUTPUT](https://github.com/ScientistAsh/tr_tjump_saxs/tree/main/TUTORIALShttps://github.com/ScientistAsh/tr_tjump_saxs/tree/main/TUTORIALS/OUTPUT/) subdirectory in the [TUTORIALS](https://github.com/ScientistAsh/tr_tjump_saxs/tree/main/TUTORIALShttps://github.com/ScientistAsh/tr_tjump_saxs/tree/main/TUTORIALS/) directory. \n",
    "\n",
    "# How to Use Jupyter Notebooks\n",
    "You can execute the code directly in this notebook or create your own notebook and copy the code there. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a0b62-afdc-4f77-ab79-93618c4d440c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "    <b><i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>&nbsp; Tips</b><br>\n",
    "    \n",
    "    <b>1.</b> To run the currently highlighted cell, hit the <code>shift</code> and <code>enter</code> keys at the same time.<br>\n",
    "    <b>2</b>. To get help with a specific function, place the cursor in the functions brackets and hit the <code>shift</code> and <code>tab</code> keys at the same time.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d2ab2-073b-4b86-bcbc-ffe4d0a11387",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"background-color: white; border: 2px solid; padding: 10px\">\n",
    "    <b><i class=\"fa fa-star\" aria-hidden=\"true\"></i>&nbsp; In the Literature</b><br>\n",
    "    \n",
    "    Our <a href=\"https://www.science.org/doi/10.1126/sciadv.adj0396\">recent paper </a> in Science Advances provides an example of the type of data, the analysis procedure, and example output for this type of data analysis.  <br> \n",
    "    \n",
    "    <p style=\"text-align:center\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936c595-a9f0-4387-9a6b-ba7d74e7a337",
   "metadata": {},
   "source": [
    "# Import Modules\n",
    "\n",
    "In order to use the `saxs_processing` module, the `tr_tjump_saxs` package needs to be imported. The dependecies will automatically be imported with the package import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c142b14-d63c-4ff3-805f-ded0030bbe71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys to allow python to use the file browser to find files\n",
    "import sys\n",
    "\n",
    "# append the path for the tr_tjump_saxs_analysis package to the PYTHONPATH\n",
    "sys.path.append(r'../')\n",
    "\n",
    "# import CH505TF_SAXS analysis dependent packages and custom functions\n",
    "from file_handling import *\n",
    "from saxs_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561aed21-e782-4394-852a-6ba7a86c9743",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b><i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>&nbsp; Tips</b><br>\n",
    "    Be sure that the path for the <code>tr_tjump_saxs</code> package appended to the <code>PYTHONPATH</code> matches the path to the repository on your machine.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517c4e29-2620-4125-bfce-d0082dcef92d",
   "metadata": {},
   "source": [
    "<a id='Overview'></a>\n",
    "\n",
    "# Overview: Finding SAXS Difference Curve Outliers\n",
    "\n",
    "The first step in analyzing TR, T-Jump SAXS data is to detect and remove outlier scattering and difference curves. During a TR, T-Jump collection, scattering curves are measured for both buffer and protein. Static SAXS scattering curves are collected in addition to \"laser off\" and \"laser on\" T-Jump scattering curves for both protein and buffer T-Jumps. The outliers for all of these sets of scattering curves needs to be determined before further analysis. \n",
    "\n",
    "In this tutorial, we will only show this processing on the T-Jump difference curves. At the end, looping over multiple time delays and data sets is explained. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd9d13-fecc-4dd6-9be9-9c03f3812656",
   "metadata": {},
   "source": [
    "# Example 1: Basic Usage\n",
    "## Step 1: Load Difference Curves\n",
    "The rest of the TR, T-Jump SAXS processing and analysis will use the difference curves. Now that the difference curves have been calculated, they can be loaded into an array using the `load_set()` function the same as was done for the SAXS scattering curves. It is always a good idea to plot the curves to make sure the data was calculated and loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86b1f2-1763-4db4-a922-c1d03623016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load difference files for iterative chi test\n",
    "diff_files = make_flist(directory='./OUTPUT/TUTORIAL3/20hz_set01/-5us_DIFF/1ms/', \n",
    "                        prefix=None, suffix='.chi')\n",
    "# sort files lists\n",
    "diff_files.sort()\n",
    "\n",
    "# load difference curves\n",
    "diff_data, diff_array, q, diff_err = load_set(flist=diff_files, delim=',', mask=0, err=False)\n",
    "\n",
    "# Create list of labels to use for plot legend\n",
    "print('Plotting difference curves')\n",
    "labs = []\n",
    "for i in diff_files:\n",
    "    labs.append(i[-9:-6])\n",
    "\n",
    "# plot difference curves as sanity check \n",
    "plot_curve(data_arr=diff_array, q_arr=q, labels=labs, qmin=0.03, qmax=0.15, imin=None, imax=None, x='scattering vector (Å)',\n",
    "            y='scattering intensity', \n",
    "            title='CH505 TR, T-Jump SAXS Difference Curves at 1ms', save=True, \n",
    "            save_dir='./OUTPUT/TUTORIAL4/PLOTS/', save_name='tutorial4_ex1_step1.png')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3dac2-c496-4c3b-a2cb-c6864e071bbc",
   "metadata": {},
   "source": [
    "# Step 2: Find and Remove Outlier Difference Curves\n",
    "\n",
    "## Step 2.1: Run Iterative $\\chi^2$ Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca10112-38e4-429c-95a6-17f5b6b49fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# run iterative chi test\n",
    "print('Running iterative chi test...')\n",
    "iterative_chi(arr=diff_array, flist=diff_files, chi_cutoff=1.5, \n",
    "              outfile='./OUTPUT/TUTORIAL4/OUTLIERS/1ms_chi_outliers.csv', calls=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e79b6d-50db-472e-a0f6-2955c21ba17e",
   "metadata": {},
   "source": [
    "## Step 2.2: Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0f619-4024-4e56-8d05-a24a4daacc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chi outliers as a list\n",
    "chi_outliers_file = './OUTPUT/TUTORIAL4/OUTLIERS/1ms_chi_outliers.csv'\n",
    "\n",
    "# read on outliers into a list\n",
    "with open(chi_outliers_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    outliers = list(reader)\n",
    "\n",
    "# created list to store chi outlier files in\n",
    "chi_outliers = []\n",
    "\n",
    "# build outlier list\n",
    "for i in outliers:\n",
    "    chi_outliers.append(i[0])\n",
    "\n",
    "# get unique set\n",
    "unique_chi = unique_set(chi_outliers)\n",
    "\n",
    "# remove outliers from difference curves\n",
    "cleaned_files, chi_outliers = remove_outliers(flist=diff_files, olist=unique_chi, \n",
    "                             fslice=[-9,-6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3170ea22-2104-4c73-9d49-896adb0ced25",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "    <i class=\"fa fa-exclamation-triangle\"></i>&nbsp; <b>Outlier Warning</b><br>\n",
    "    The <code>remove_outliers</code> function determines the number of files in the input list and outlier list and determines if the remaining number of files matches what is expected based on these numbers. This will work without issues when loading an outlier list and a file_list set. However, if you are working through the processing workflow and are running the <code>remove_outliers</code> immediately after running the <code>iterative_chi</code> function, the diff_files list input into the <code>remove_outliers</code> function will already have most of the outliers removed but the outlier list will include all of the determined outliers. This means that you may see a warning indicating the resulting file list does not contain the amount expected based on the input lists. Generally, this can be ignored if you are sure number of remaining files is correct. Otherwise, double-check this by making sure that the number of files printed at the end of the printed statement matches the number of files the <code>remove_outliers</code> warning indicates.\n",
    "    </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05f2dd-c395-49e3-bcb8-22fdbf7bdc2f",
   "metadata": {},
   "source": [
    "Notice that the number of files remaining after outlier removal is 217, which matches the 217 files left after the `iterative_chi` analysis. Before moving on, we need to reload the `diff_array` because we last loaded this array before removing the outliers and we now need to remove this data from our diff_array.\n",
    "\n",
    "## Step 2.3: Reload diff_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9bd53a-09fb-41d0-9e97-9e17f53c1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort files lists\n",
    "cleaned_files.sort()\n",
    "\n",
    "# load difference curves\n",
    "diff_data, diff_array, q, diff_err = load_set(flist=cleaned_files, delim=',', mask=0, err=False)\n",
    "\n",
    "# Create list of labels to use for plot legend\n",
    "print('Plotting difference curves')\n",
    "labs = []\n",
    "for i in cleaned_files:\n",
    "    labs.append(i[-9:-6])\n",
    "\n",
    "# plot difference curves as sanity check \n",
    "plot_curve(data_arr=diff_array, q_arr=q, labels=labs, qmin=0.03, qmax=0.15, imin=None, imax=None, x='scattering vector (Å)',\n",
    "            y='scattering intensity', \n",
    "            title='CH505 TR, T-Jump SAXS Difference Curves at 1ms', save=True, \n",
    "            save_dir='./OUTPUT/TUTORIAL4/PLOTS/', save_name='tutorial4_ex1_step2.png')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38a982-cb91-496a-b784-ec919b26c9b9",
   "metadata": {},
   "source": [
    "# Step 3: Calculate the Average Difference Curve\n",
    "\n",
    "The last and final step of the TR, T-Jump SAXS data processing workflow is to determine the average curves and standard error. Here, we will use the above calculated difference curves for the 1ms time delay to calculate the average 1ms difference curve and the standrd error of the mean. \n",
    "\n",
    "## Step 3.1: Get Average Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a66ab-057d-45f1-9150-9f58a2b2ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get avg curve\n",
    "avg_curve = diff_array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6aac82-b5e6-406c-bea0-6d2b37fc5a6e",
   "metadata": {},
   "source": [
    "## Step 3.2: Get Standard Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec838658-e916-4c37-bf49-4d0f7119f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get standard deviation\n",
    "curve_std = diff_array.std(axis=0)\n",
    "\n",
    "# get standard error\n",
    "curve_err = curve_std/math.sqrt(len(diff_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31662c2a-c62f-4c22-84f0-3a50c737b8d0",
   "metadata": {},
   "source": [
    "## Step 3.3: Save Average Curve and SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b69550-39c9-47c1-9de3-0f81ecb6aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat avg curve and sem into single array\n",
    "avg_sem = np.array([avg_curve, curve_err])\n",
    "\n",
    "make_dir('./OUTPUT/TUTORIAL4/AVERAGE_DIFF/')\n",
    "\n",
    "# save avg_curvbe and sem to file\n",
    "np.savetxt('./OUTPUT/TUTORIAL4/AVERAGE_DIFF/1ms.csv', \n",
    "           np.c_[q, avg_curve, curve_err], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17136372-ce97-4d99-89cb-a531b87ea43f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "    <i class=\"fa fa-exclamation-triangle\"></i>&nbsp; <b>ATSAS Software</b><br>\n",
    "    The <a href=\"https://www.embl-hamburg.de/biosaxs/software.html\">ATSAS Software </a> works better with space-delimitted '.dat' files. The current version of the <a href=\"https://gitlab.oit.duke.edu/tr_t-jump_saxs/y22-23/-/tree/main?ref_type=heads\">tr_tjump_saxs </a> package, some the the analysis has to be performed in ATSAS so it may be more convenient to save the file in the ATSAS-compatible format.  \n",
    "    </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb9d77-1bb5-4f1e-b11f-38a62a1198fd",
   "metadata": {},
   "source": [
    "## Step 3.4: Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f3390-ddb9-4ae9-9f3c-22da29e1bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all data\n",
    "print('Plotting data...')\n",
    "\n",
    "ax = plt.axes([0.125,0.125, 5, 5])\n",
    "\n",
    "plt.plot(q, avg_sem[0], linewidth=2)\n",
    "plt.fill_between(q, avg_sem[0]-avg_sem[1], avg_sem[0]+avg_sem[1], alpha=0.5)\n",
    "plt.xlabel('q ($\\AA^{-1}$)', fontsize=70, fontweight='bold')\n",
    "plt.ylabel('Change in Scattering Intensity', fontsize=70, fontweight='bold')\n",
    "plt.title('CH505TF Average SAXS Difference Curve at 1ms', fontsize=80, fontweight='bold')\n",
    "plt.xticks(fontsize=60)\n",
    "plt.yticks(fontsize=60)\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    ax.spines[axis].set_linewidth(5)\n",
    "\n",
    "zoom = plt.axes([-5, 0.5, 4, 4])\n",
    "plt.plot(q, avg_sem[0], linewidth=2)\n",
    "plt.fill_between(q, avg_sem[0]-avg_sem[1], avg_sem[0]+avg_sem[1], alpha=0.5)\n",
    "# style plot\n",
    "plt.ylabel('Change in Scattering Intensity', fontsize=70, fontweight='bold')\n",
    "plt.xlabel('q ($\\AA^{-1}$)', fontsize=70, fontweight='bold')\n",
    "plt.xticks(fontsize=55)\n",
    "plt.yticks(fontsize=55)\n",
    "plt.xlim([0.02, 0.1])\n",
    "plt.title('CH505TF Average SAXS Difference Curve at 1ms\\nZoom', fontsize=80, fontweight='bold')\n",
    "\n",
    "for axis in ['top','bottom','left','right']:\n",
    "    zoom.spines[axis].set_linewidth(5)\n",
    "\n",
    "# mark inset\n",
    "mark_inset(ax, zoom, loc1=1, loc2=4, fc=\"none\", ec=\"0.5\", linewidth=4)\n",
    "\n",
    "\n",
    "plt.savefig('./OUTPUT/TUTORIAL4/AVERAGE_DIFF/tutorial4_ex1_step3.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff8fcf-c9ae-4626-b1de-642cadd1655b",
   "metadata": {},
   "source": [
    "This is the entire workflow for processing SAXS data. When processing TR, T-Jump SAXS data it is usually more convenient to process all time delays at once. Now we show how to combine the analysis described above to iterate through all time delays at once. \n",
    "\n",
    "# Example 2: Looping over Multiple Time Delays and Data Sets\n",
    "\n",
    "## Step 1: Define Dataset Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f95d2-d85e-40de-a7f2-ca55926c1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define det numbers\n",
    "sets = ['20hz_set02', '20hz_set02', '20hz_set02',\n",
    "        '20hz_set01', '20hz_set01', '20hz_set01', '20hz_set01', '20hz_set01',\n",
    "        '20hz_set03', '20hz_set03', '20hz_set03',\n",
    "        '5hz_set01', '5hz_set01', '5hz_set01']\n",
    "\n",
    "# define datasets\n",
    "time_delays = ['1.5us', '3us', '5us', \n",
    "               '10us', '50us', '100us', '500us', '1ms',\n",
    "               '5us', '300us', '1ms',\n",
    "               '1ms', '10ms', '100ms']\n",
    "\n",
    "# define data directories\n",
    "directories = ['./OUTPUT/TUTORIAL3/20hz_set02/', './OUTPUT/TUTORIAL3/20hz_set02/',\n",
    "               './OUTPUT/TUTORIAL3/20hz_set02/', './OUTPUT/TUTORIAL3/20hz_set01/',\n",
    "               './OUTPUT/TUTORIAL3/20hz_set01/','./OUTPUT/TUTORIAL3/20hz_set01/',\n",
    "               './OUTPUT/TUTORIAL3/20hz_set01/', './OUTPUT/TUTORIAL3/20hz_set01/',\n",
    "               './OUTPUT/TUTORIAL3/20hz_set03/', './OUTPUT/TUTORIAL3/20hz_set03/',\n",
    "               './OUTPUT/TUTORIAL3/20hz_set03/', './OUTPUT/TUTORIAL3/5hz_set01/',\n",
    "               './OUTPUT/TUTORIAL3/5hz_set01/', './OUTPUT/TUTORIAL3/5hz_set01/'] \n",
    "\n",
    "prefixes = ['20hz_set02_', '20hz_set02_', '20hz_set02_',\n",
    "           '20hz_set01_','20hz_set01_','20hz_set01_','20hz_set01_','20hz_set01_',\n",
    "           '20hz_set03_', '20hz_set03_', '20hz_set03_',\n",
    "           '5hz_set01_', '5hz_set01_', '5hz_set01_']\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666858c1-4873-41cb-a2ae-83920dc9480d",
   "metadata": {},
   "source": [
    "## Step 2: Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be3e5e-98c4-4156-aea9-ef33c1fb7818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# loop over time delay, make a file lists, and load the curve set\n",
    "for t,d,p,s in zip(time_delays, directories, prefixes, sets):\n",
    "    print('Loading ' + str(t) + ' curves')\n",
    "    \n",
    "    # load difference files for iterative chi test\n",
    "    diff_files = make_flist(directory=str(d) + '-5us_DIFF/' + str(t) + '/', \n",
    "                            prefix=str(p), suffix='_Q.chi')\n",
    "\n",
    "    # sort files lists\n",
    "    diff_files.sort()\n",
    "\n",
    "    # load difference curves\n",
    "    diff_data, diff_array, q, diff_err = load_set(flist=diff_files, delim=',', mask=0, err=False)\n",
    "\n",
    "    # Create list of labels to use for plot legend\n",
    "    print('Plotting difference curves')\n",
    "    \n",
    "    labs = []\n",
    "    for i in diff_files:\n",
    "        labs.append(i[-9:-6])\n",
    "\n",
    "    # plot difference curves as sanity check \n",
    "    plot_curve(data_arr=diff_array, q_arr=q, labels=labs, qmin=0.03, qmax=0.15, imin=None, imax=None, x='scattering vector (Å)',\n",
    "                y='scattering intensity', \n",
    "                title='CH505 TR, T-Jump SAXS Difference Curves at ' + str(t), save=True, \n",
    "                save_dir='./OUTPUT/TUTORIAL4/PLOTS/', save_name='tutorial4_ex2_before_processing.png')  \n",
    "    \n",
    "    \n",
    "    print('Done loading data!')\n",
    "    \n",
    "    # run iterative chi test\n",
    "    print('Running iterative chi test...')\n",
    "    iterative_chi(arr=diff_array, flist=diff_files, chi_cutoff=1.5, \n",
    "                  outfile='./OUTPUT/TUTORIAL4/OUTLIERS/' + str(t) + '_chi_outliers.csv', calls=1)\n",
    "    \n",
    "    # load chi outliers as a list\n",
    "    chi_outliers_file = './OUTPUT/TUTORIAL4/OUTLIERS/1ms_chi_outliers.csv'\n",
    "\n",
    "    # read on outliers into a list\n",
    "    with open(chi_outliers_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        outliers = list(reader)\n",
    "\n",
    "    # created list to store chi outlier files in\n",
    "    chi_outliers = []\n",
    "\n",
    "    # build outlier list\n",
    "    for i in outliers:\n",
    "        chi_outliers.append(i[0])\n",
    "\n",
    "    # get unique set\n",
    "    unique_chi = unique_set(chi_outliers)\n",
    "\n",
    "    # remove outliers from difference curves\n",
    "    cleaned_files, chi_outliers = remove_outliers(flist=diff_files, olist=unique_chi, \n",
    "                                 fslice=[-9,-6])\n",
    "\n",
    "    \n",
    "    # sort files lists\n",
    "    cleaned_files.sort()\n",
    "\n",
    "    # load difference curves\n",
    "    diff_data, diff_array, q, diff_err = load_set(flist=cleaned_files, delim=',', mask=0, err=False)\n",
    "\n",
    "    # Create list of labels to use for plot legend\n",
    "    print('Plotting difference curves')\n",
    "    labs = []\n",
    "    for i in cleaned_files:\n",
    "        labs.append(i[-9:-6])\n",
    "\n",
    "    # plot difference curves as sanity check \n",
    "    plot_curve(data_arr=diff_array, q_arr=q, labels=labs, qmin=0.03, qmax=0.15, imin=None, imax=None, x='scattering vector (Å)',\n",
    "                y='scattering intensity', \n",
    "                title='CH505 TR, T-Jump SAXS Difference Curves at ' + str(t), save=True, \n",
    "                save_dir='./OUTPUT/TUTORIAL4/PLOTS/', save_name='tutorial4_ex2_cleaned_files.png')  \n",
    "\n",
    "    # get avg curve\n",
    "    avg_curve = diff_array.mean(axis=0)\n",
    "    \n",
    "    # get standard deviation\n",
    "    curve_std = diff_array.std(axis=0)\n",
    "\n",
    "    # get standard error\n",
    "    curve_err = curve_std/math.sqrt(len(diff_array))\n",
    "    \n",
    "    # concat avg curve and sem into single array\n",
    "    avg_sem = np.array([avg_curve, curve_err])\n",
    "\n",
    "    make_dir('./OUTPUT/TUTORIAL4/AVERAGE_DIFF/')\n",
    "\n",
    "    # save avg_curve and sem to file\n",
    "    np.savetxt('./OUTPUT/TUTORIAL4/AVERAGE_DIFF/' + str(t) + '.csv', \n",
    "               np.c_[q, avg_curve, curve_err], delimiter=\",\")\n",
    "    \n",
    "    # plot all data\n",
    "    print('Plotting data...')\n",
    "\n",
    "    ax = plt.axes([0.125,0.125, 5, 5])\n",
    "\n",
    "    plt.plot(q, avg_sem[0], linewidth=2)\n",
    "    plt.fill_between(q, avg_sem[0]-avg_sem[1], avg_sem[0]+avg_sem[1], alpha=0.5)\n",
    "    plt.xlabel('q ($\\AA^{-1}$)', fontsize=70, fontweight='bold')\n",
    "    plt.ylabel('Change in Scattering Intensity', fontsize=70, fontweight='bold')\n",
    "    plt.title('CH505TF Average SAXS Difference Curve at ' + str(t), fontsize=80, fontweight='bold')\n",
    "    plt.xticks(fontsize=60)\n",
    "    plt.yticks(fontsize=60)\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(5)\n",
    "\n",
    "    zoom = plt.axes([-5, 0.5, 4, 4])\n",
    "    plt.plot(q, avg_sem[0], linewidth=2)\n",
    "    plt.fill_between(q, avg_sem[0]-avg_sem[1], avg_sem[0]+avg_sem[1], alpha=0.5)\n",
    "    # style plot\n",
    "    plt.ylabel('Change in Scattering Intensity', fontsize=70, fontweight='bold')\n",
    "    plt.xlabel('q ($\\AA^{-1}$)', fontsize=70, fontweight='bold')\n",
    "    plt.xticks(fontsize=55)\n",
    "    plt.yticks(fontsize=55)\n",
    "    plt.xlim([0.02, 0.1])\n",
    "    plt.title('CH505TF Average SAXS Difference Curve at ' + str(t) + '\\nZoom', fontsize=80, fontweight='bold')\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        zoom.spines[axis].set_linewidth(5)\n",
    "\n",
    "    # mark inset\n",
    "    mark_inset(ax, zoom, loc1=1, loc2=4, fc=\"none\", ec=\"0.5\", linewidth=4)\n",
    "\n",
    "\n",
    "    plt.savefig('./OUTPUT/TUTORIAL4/PLOTS/' + str(t) + '_avg_diff.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8753a-0507-4116-8682-2d0cb3107487",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "    <i class=\"fa fa-check-circle\"></i>&nbsp; <b>Congratulations!</b><br>\n",
    "    You completed the fourth tutorial! Continue with <a href=\"https://gitlab.oit.duke.edu/tr_t-jump_saxs/y22-23/-/blob/main/TUTORIALS/tutorial5_saxs_modeling.ipynb?ref_type=heads\">Tutorial 5</a> to continue assess your data for systematic errors.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ed191-9e7f-4f16-9d70-8513268807e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
